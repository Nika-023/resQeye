# resQeye

AI powered rescue drone project created for competitions Millennium and Leonardo.

---

## Person Detection Code Explanation

### კოდის ახსნა

- `ret, frame = cap.read()`  
  აქ ხდება ახალი კადრის წაკითხვა კამერიდან.  
  თუ კადრი წარმატებით წაიკითხა, `ret` იქნება მართალი (`True`), ხოლო `frame` შეიცავს იმ კადრის მონაცემებს.  
  თუ კადრი აღარ არის (ვიდეო დასრულდა ან კამერა გაუჩერებელია), `ret` იქნება False და ციკლი შეჩერდება.

- `frame.shape[:2]`  
  აქ ვიღებთ კადრის სიმაღლის (height) და სიგანის (width) ზომებს პიქსელებში.  
  `[:2]` ნიშნავს, რომ ვიღებთ მხოლოდ პირველ ორ მნიშვნელობას მასივიდან, რაც არის სიმაღლე და სიგანე.  
  მაგალითად, თუ კადრის ზომაა 1920x1080, მაშინ `height = 1080` და `width = 1920`.

- `scale = min(MAX_WIDTH / width, MAX_HEIGHT / height)`  
  ვანგარიშობთ კადრის გადაფართოების კოეფიციენტს ისე, რომ ახალი ზომა არ აღემატებოდეს მაქსიმალურ პარამეტრებს.  
  მაგალითად, თუ კადრი არის 1920x1080 და ჩვენ გვინდა მაქსიმუმ 1280x720, მაშინ ვანგარიშობთ:  
  1280/1920 = 0.6667 და 720/1080 = 0.6667, ანუ კადრს შევამცირებთ 66.67%-ით. ფუნქცია min() გვჭირდება, რადგან ზოგი ვიდეო არანორმალურ რესოლუციაზეა (მაგალითად 4:3 ან 1:1), ამიტომ მინიმალური უნდა ავიღოთ ორი გაყოფისგან, რომ არ მივიღოთ ანომალიური კადრი.

- `new_size = (int(width * scale), int(height * scale))`  
  ახალი ზომის გამოთვლა (ინტეჟერებად).  
  მაგალითად, 1920 * 0.6667 ≈ 1280 და 1080 * 0.6667 ≈ 720.

- `resized_frame = cv2.resize(frame, new_size)`  
  გადავიყვანთ კადრს ამ ახალ ზომაში.  
  ეს აუცილებელია, რადგან მოდელი უფრო სწრაფად და ეფექტურად მუშაობს მცირე ზომის კადრებზე.

- `results = model(resized_frame)`  
  მოდელს ვუგზავნით კადრს, რომელიც დაბრუნებს ამ კადრში ამოცნობილ ობიექტებს (ამ შემთხვევაში, ადამიანებს — ანუ კლასი 0).

- `for *box, conf, cls in results.xyxy[0]:`  
  მოდელი გვაძლევს თითოეული აღმოჩენილი ობიექტის მონაცემებს:  
  - `*box` — ყუთის კოორდინატები (x1, y1, x2, y2), რომელიც ხაზავს ადამიანის ადგილს კადრზე,  
    Python-ში `*` ოპერატორი გამოიყენება რამდენიმე მნიშვნელობის გაშლისთვის (https://peps.python.org/pep-3132/).  
  - `conf` — ნდობის დონე (რამდენად დარწმუნებულია მოდელი ამ ამოცნობაში),  
  - `cls` — კლასის ნომერი (აქ მხოლოდ ადამიანი - 0).

- `if conf >= 0.4:`  
  თუ ნდობის დონე არის 40%-ზე მაღალი ან ტოლი, მაშინ მივიჩნევთ ამ ამოცნობას სანდოდ და ვაგრძელებთ.

- `x1, y1, x2, y2 = [int(mshia) for mshia in box]` (ან `x1, y1, x2, y2 = map(int, box)`)  
  ყუთის კოორდინატებს ვაქცევთ მთელ რიცხვებად, რადგან პიქსელების პოზიციები არ შეიძლება იყოს არასრული.  
  მაგალითად, 345.67 დაიყვანება 345.

- `cv2.rectangle(resized_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)`  
  მწვანე ფერის (RGB: 0, 255, 0) ყუთის დახატვა იმ ადგილზე, სადაც აღმოჩენილია ადამიანი.  
  ბოლო პარამეტრი 2 არის ხაზის სისქე.

- `cv2.putText(resized_frame, 'Person', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)`  
  ყუთის ზემოთ ვამატებთ ტექსტს "Person", რათა დავახასიათოთ, რა არის ამ ყუთში.  
  ტექსტის ზომა, ფერი და სისქე არის განსაზღვრული.
